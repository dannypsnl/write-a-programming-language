<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Parser · write-a-programming-language</title><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.039/juliamono-regular.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">write-a-programming-language</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Overview</a></li><li><span class="tocitem">Chapters</span><ul><li><a class="tocitem" href="../chapter_1/">Chapter 1: Type Checking</a></li><li><a class="tocitem" href="../chapter_2/">Chapter 2: Type Inference</a></li><li><a class="tocitem" href="../chapter_3/">Chapter 3: Lambda Calculus</a></li><li><input class="collapse-toggle" id="menuitem-2-4" type="checkbox"/><label class="tocitem" for="menuitem-2-4"><span class="docs-label">Polymorphsim &amp; Advanced Type Inference</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../ch4/ad-hoc-poly/">Ad-hoc polymorphism</a></li><li><a class="tocitem" href="../ch4/parametric-poly/">Parametric polymorphism</a></li><li><a class="tocitem" href="../ch4/subtyping/">Subtyping</a></li><li><a class="tocitem" href="../ch4/row-poly/">row polymorphism</a></li></ul></li><li><a class="tocitem" href="../chapter_5/">Chapter 5: Complicated Inference</a></li><li><a class="tocitem" href="../chapter_6/">Chapter 6: Lambda Cube</a></li><li><a class="tocitem" href="../chapter_7/">Chapter 7: Dependent Type</a></li><li><a class="tocitem" href="../chapter_8/">Chapter 8: Curry-Howard Correspondence</a></li><li><a class="tocitem" href="../chapter_9/">Chapter 9: Substructural Type</a></li><li><a class="tocitem" href="../chapter_10/">Chapter 10: Refinement Type</a></li></ul></li><li><span class="tocitem">Appendix</span><ul><li class="is-active"><a class="tocitem" href>Parser</a><ul class="internal"><li><a class="tocitem" href="#Simple-parser-and-why-we-have-next-section"><span>Simple parser and why we have next section</span></a></li><li><a class="tocitem" href="#Lexer"><span>Lexer</span></a></li><li><a class="tocitem" href="#Manual-parser"><span>Manual parser</span></a></li><li><a class="tocitem" href="#Combinator"><span>Combinator</span></a></li><li><a class="tocitem" href="#Conclusion"><span>Conclusion</span></a></li></ul></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Appendix</a></li><li class="is-active"><a href>Parser</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Parser</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/dannypsnl/write-a-programming-language/blob/master/src/appendix_parser.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Parser"><a class="docs-heading-anchor" href="#Parser">Parser</a><a id="Parser-1"></a><a class="docs-heading-anchor-permalink" href="#Parser" title="Permalink"></a></h1><p>I have to say I have no idea why most compiler books spent time on Parser, of course this is really complex topic, but practical language usually didn&#39;t need the complex techiology. But at here I still would list the common tools would be there for developing a Parser.</p><p>Before that, we must know why we need the Parser, the Parser was a tool to translate the language in our mind into another language to run on certain environment. The most common example was compiler compile the language to assembly, but why assembly language? Because the environment in case was OS provide the tool called assembler which can translate assembly to machine code which can run on the real machine(or more specific, run by CPU). Or like TypeScript, Elm and GHCJs compile the origin language to another high-level language JavaScript.</p><p>So the point was we would like to run a program, and we would find out how to run it on our target platform. When you learn these stuffs, I believe there are many resources keep mention AST. But what&#39;s AST? AST was abstract syntax tree, or to be honestly, our real language. Sure, the syntax was not language, or at least just the outlooking part. The all important things are our mind concept, and the language just a way to express our mind with some trade-off. What trade-off? For example a language can write:</p><pre><code class="nohighlight hljs">print hello, world</code></pre><p>Of course was possible, however, would be hard to read in more complex place. So rather than make Compiler handles it, we choose to let people(programmer) handles <code>string</code>. Now the code became:</p><pre><code class="nohighlight hljs">print &quot;hello, world&quot;</code></pre><p>It looks more clear. But the example can be more complex, remember currently we are say <code>print</code> takes <code>&quot;hello, world&quot;</code> to do something, now we extend the example:</p><pre><code class="nohighlight hljs">print &quot;hello, &quot; user_input</code></pre><p><code>user_input</code> was another function which get input from user, no matter how did it work, now we have trouble: We should <strong>print</strong> <code>hello, &lt;function&gt;</code> or <code>hello, Danny</code>(if user type in <code>Danny</code>)?</p><p>In fact, compiler can not do the decision for you, whatever which behavior it picked would make functionality missing. Sometimes we are really want to print out the function value. So we introduce parenthesis in case:</p><pre><code class="nohighlight hljs">print(&quot;hello, &quot;, user_input())
# or
print &quot;hello, &quot; (user_input)</code></pre><p>The first one was picked by C family, and second one was using by ML family, both has cons and pros. We would keep mention these issues.</p><h2 id="Simple-parser-and-why-we-have-next-section"><a class="docs-heading-anchor" href="#Simple-parser-and-why-we-have-next-section">Simple parser and why we have next section</a><a id="Simple-parser-and-why-we-have-next-section-1"></a><a class="docs-heading-anchor-permalink" href="#Simple-parser-and-why-we-have-next-section" title="Permalink"></a></h2><p>In this section we would use Perl6 to build a parser. Parser can be generated? Sure, but I do not recommend it in production. But for simple stuff it was fine.</p><p>Here we were going to talk about natural number arithmetic syntax which supprts plus: <code>+</code>, times(multiple): <code>*</code>, minus: <code>-</code> and divide: <code>/</code>.</p><pre><code class="language-perl6 hljs">grammar Calculator {
    token TOP { &lt;calc-op&gt; }

    proto rule calc-op          {*}
          rule calc-op:sym&lt;mult&gt; { &lt;num&gt; &#39;*&#39; &lt;num&gt; }
          rule calc-op:sym&lt;div&gt; { &lt;num&gt; &#39;/&#39; &lt;num&gt; }
          rule calc-op:sym&lt;add&gt; { &lt;num&gt; &#39;+&#39; &lt;num&gt; }
          rule calc-op:sym&lt;sub&gt; { &lt;num&gt; &#39;-&#39; &lt;num&gt; }
    # just like regex, \d+ is at least one digit
    token num { \d+ }
}</code></pre><p>This is a very short syntax, even C lanugage syntax has 954 lines: https://github.com/antlr/grammars-v4/blob/master/c/C.g4 , cpp even has 1940 lines: https://github.com/antlr/grammars-v4/blob/master/cpp/CPP14.g4 in Antlr4(another parser generator).</p><p>Forget about that, at here code generator was really useful, we can quickly generate the Parser for our purpose. Then we can create an interpreter based on it:</p><pre><code class="language-perl6 hljs">class Calculations {
    method TOP              ($/) { make $&lt;calc-op&gt;.made; }
    # if you are not familiar with Perl just like me, notice that `calc-op` mapping to each grammar
    method calc-op:sym&lt;mult&gt; ($/) { make [*] $&lt;num&gt; }
    method calc-op:sym&lt;div&gt; ($/) { make [/] $&lt;num&gt; }
    method calc-op:sym&lt;add&gt; ($/) { make [+] $&lt;num&gt;; }
    method calc-op:sym&lt;sub&gt; ($/) { make [-] $&lt;num&gt;; }
}

say &#39;2+2 = &#39; ~ Calculator.parse(&#39;2+2&#39;, actions =&gt; Calculations).made;
say &#39;2*3 = &#39; ~ Calculator.parse(&#39;2*3&#39;, actions =&gt; Calculations).made;</code></pre><p>This one basically not good enough, it can&#39;t handle parentheses, can&#39;t handle <code>2 * 2 + 3</code>. But anyway shows how interpreter work.</p><p>Now consider a manual parser, how would it looks like? It actually easy to build up. Consider the following Java program:</p><pre><code class="language-java hljs">Scanner s = new Scanner(input);
StringBuilder number = new StringBuilder(&quot;&quot;);
char c = s.next().charAt(0);
while (Character.isDigit(c)) {
    number.append(c);
    c = s.next().charAt(0);
}
// now c must not a digit
while (Character.isSpace(c)) {
    c = s.next().charAt(0); // skip whitespace
}
if (c == &#39;+&#39;) {
    c = s.next().charAt(0);
} else {
    throw new SyntaxException(&quot;allow + operator only&quot;);
}
while (Character.isSpace(c)) {
    c = s.next().charAt(0); // skip whitespace
}
StringBuilder number2 = new StringBuilder(&quot;&quot;);
char c = s.next().charAt(0);
while (Character.isDigit(c)) {
    number2.append(c);
    c = s.next().charAt(0);
}
return new BinaryExpression(number, number2, Operator(&quot;+&quot;));</code></pre><p>This is of course too exaggerated, but can show why handling input stream is not a good idea. That&#39;s why we introduce Lexer layer.</p><h2 id="Lexer"><a class="docs-heading-anchor" href="#Lexer">Lexer</a><a id="Lexer-1"></a><a class="docs-heading-anchor-permalink" href="#Lexer" title="Permalink"></a></h2><p>Lexer is an optional, the correct way to describe it was a helper component, we would need it when the token was trying to reduce the concept we have to consider. If we don&#39;t use lexer, when we parsing</p><pre><code class="nohighlight hljs">class Foo {}</code></pre><p>we could write down:</p><pre><code class="language-py hljs">identifier = take_char_until_one_of([&#39; &#39;, &#39;\n&#39;])
if identifier == &quot;class&quot;:
    name_of_class = take_char_until_one_of([&#39; &#39;, &#39;\n&#39;])
    require(&#39;{&#39;)
    require(&#39;}&#39;)
else:
    # parse different rule</code></pre><p>Which was very low-level program, we have to handle each space and newline and remember when we don&#39;t need them. For many language we can extract out lexer/tokenizer to do these. The idea was we don&#39;t have to directly work with string, but with token, a token could contain <code>location</code>, <code>content</code>, <code>type</code> these information to help parser keep doing the parsing. A lexer can directly skip whitespace and newline, update location information and normalize the content of token(for example we can parse int or parse float before the token sent to parser).</p><p>Here, I show a naive Lexer written in Rust:</p><pre><code class="language-rust hljs">// first need to define Location
#[derive(Clone, Debug)]
struct Location {
    file_name: String,
    // line, column is the pair of location, use start point of token
    line: u32,
    column: u32,
    // start, end is the start offset to end offset for a token, for example: `let` at 0 has start: 0 and end: 3
    start: u32,
    end: u32,
}

impl Location {
    pub fn new&lt;T: ToString&gt;(
        file_name: T,
        line: u32,
        column: u32,
        start: u32,
        end: u32,
    ) -&gt; Location {
        Location {
            file_name: file_name.to_string(),
            line,
            column,
            start,
            end,
        }
    }
}

// then need some Token Type
#[derive(Clone, Debug, PartialEq)]
enum TkType {
    EOF,
    Identifier,
    KeywordLet,
    Integer,
}

// A Token has location, type and value
struct Token(Location, TkType, String);

// A lexer moving between states, by each state has a behavior produce new state, and at the end must reach EOF to complete tokenizing, ok, so we can have such definition:
enum State {
    Fn(fn(&amp;mut Lexer) -&gt; State),
    EOF,
}

// Now define Lexer
struct Lexer {
    file_name: String,
    code: Vec&lt;char&gt;,
    tokens: Vec&lt;Token&gt;,
    state_fn: State,
    start: usize,
    offset: usize,
    // (line, pos) represent the position for user
    pos: u32,
    line: u32,
}

// several helpers
impl Lexer {
    fn new&lt;T: Into&lt;String&gt;&gt;(file_name: T, code: T) -&gt; Lexer {
        Lexer {
            file_name: file_name.into(),
            code: code.into().chars().collect(),
            tokens: vec![],
            state_fn: State::Fn(whitespace),
            start: 0,
            offset: 0,
            pos: 0,
            line: 1, // line start from 1
        }
    }

    fn ignore(&amp;mut self) {
        self.pos += (self.offset - self.start) as u32;
        self.start = self.offset;
    }
    fn peek(&amp;self) -&gt; Option&lt;char&gt; {
        match self.code.get(self.offset) {
            Some(c) =&gt; Some(*c),
            None =&gt; None,
        }
    }
    fn next(&amp;mut self) -&gt; Option&lt;char&gt; {
        self.offset += 1;
        self.peek()
    }
    fn new_token(&amp;mut self, token_type: TkType, value: String) -&gt; Token {
        Token(
            Location::new(
                self.file_name.clone(),
                self.line,
                self.pos,
                self.start as u32,
                self.offset as u32,
            ),
            token_type,
            value,
        )
    }
    fn emit(&amp;mut self, token_type: TkType) {
        let s: String = self.code[self.start..self.offset].into_iter().collect();
        let tok = match s.as_str() {
            &quot;let&quot; =&gt; self.new_token(TkType::KeywordLet, s),
            _ =&gt; self.new_token(token_type.clone(), s),
        };
        self.tokens.push(tok);
        self.ignore();
    }
}

fn whitespace(lexer: &amp;mut Lexer) -&gt; State {
    while let Some(c) = lexer.peek() {
        if c == &#39; &#39; || c == &#39;\r&#39; || c == &#39;\n&#39; {
            if c == &#39;\n&#39; {
                lexer.next();
                lexer.start = lexer.offset;
                lexer.pos = 0;
                lexer.line += 1;
            } else {
                lexer.next();
            }
        } else {
            break;
        }
    }
    lexer.ignore();

    match lexer.peek() {
        Some(_c @ &#39;0&#39;..=&#39;9&#39;) =&gt; State::Fn(number),
        Some(c) =&gt; {
            if in_identifier_set(c) {
                State::Fn(ident)
            } else {
                unimplemented!(&quot;char: `{}`&quot;, c);
            }
        }
        None =&gt; State::EOF,
    }
}

fn in_identifier_set(c: char) -&gt; bool {
    c.is_alphanumeric() || c == &#39;_&#39;
}
fn ident(lexer: &amp;mut Lexer) -&gt; State {
    while let Some(c) = lexer.next() {
        if !in_identifier_set(c) {
            break;
        }
    }
    lexer.emit(TkType::Identifier);
    State::Fn(whitespace)
}
fn number(lexer: &amp;mut Lexer) -&gt; State {
    while let Some(c) = lexer.next() {
        if !c.is_digit(10) {
            break;
        }
    }
    lexer.emit(TkType::Integer);
    State::Fn(whitespace)
}

pub fn lex&lt;T: Into&lt;String&gt;&gt;(file_name: T, source: T) -&gt; Vec&lt;Token&gt; {
    let mut lexer = Lexer::new(file_name, source);
    // tokenizing is just moving between state when possible
    while let State::Fn(f) = lexer.state_fn {
        lexer.state_fn = f(&amp;mut lexer);
    }
    // emit final EOF to help Parser report EOF problem(optional, also can use no more token as EOF)
    lexer.emit(TkType::EOF);
    lexer.tokens
}</code></pre><h2 id="Manual-parser"><a class="docs-heading-anchor" href="#Manual-parser">Manual parser</a><a id="Manual-parser-1"></a><a class="docs-heading-anchor-permalink" href="#Manual-parser" title="Permalink"></a></h2><p>A manual parser is powerful, but on the other hand it takes a lot of effort. Before you jump into writing a manual parser and never go back again, ensure that parser generator cannot handle your case.</p><p>Write a manual parser didn&#39;t need many parsing background knowledge, surprising, but heavy repetitive work. Because simply porting <strong>LL</strong> syntax can handle about 90% job. For example, an assignment syntax <code>&lt;type&gt; &lt;name&gt; = &lt;expr&gt;;</code> can use the following parser:</p><pre><code class="language-py hljs">typ = parse_type()
name = parse_identifier()
expect_symbol(&#39;=&#39;)
expr = parse_expr()
expect_symbol(&#39;;&#39;)
return Assign(typ=typ, name=name, expr=expr)</code></pre><p>However, there has an annoying case: <strong>expression parsing</strong>. How this became the big problem for newbies? If we follow <strong>LL</strong> strict conversion from syntax as below:</p><pre><code class="language-bnf hljs">expr ::=
  expr &quot;*&quot; expr
  | expr &quot;+&quot; expr
  | // ignore others</code></pre><p>the conversion is:</p><pre><code class="language-py hljs">def parse_expr():
    left_expr = parse_expr()
    op = expect_oneof(&#39;*&#39;, &#39;+&#39;)
    right_expr = parse_expr()
    return BinaryExpression(left_expr, op, right_expr)</code></pre><p>This is <strong>left recursive</strong>, your parser would keep calling <code>parse_expr</code> and never end(or stack overflow, depend on which language you&#39;re using).</p><p>Clever as you, might thought out how to fix this quickly:</p><pre><code class="language-bnf hljs">expr ::=
  integer &quot;*&quot; expr
  | integer &quot;+&quot; expr
  | integer</code></pre><p>here is conversion:</p><pre><code class="language-py hljs">def parse_expr():
    left_expr = parse_integer()
    try:
        op = expect_oneof(&#39;*&#39;, &#39;+&#39;)
        try:
            right_expr = parse_expr()
            return BinaryExpression(left_expr, op, right_expr)
        except:
            # keep throw up the parse error
            raise
    except:
        # to simplify example, assuming `expect_oneof` is under the control and won&#39;t throw unexpected exception
        # no right hand side expression
        return left_expr</code></pre><p>It would work, until you have to handle <strong>operator precedence</strong>. For example, <code>*</code> would usually be applied before <code>+</code>. As clever as you, get the solution quickly again:</p><pre><code class="language-bnf hljs">expr ::=
  term &quot;*&quot; expr
  | term
term ::=
  integer &quot;+&quot; expr
  | integer</code></pre><p>However, the implementation work became quick heavy now.</p><p>To solve all problem in once, we need a better way to handle this, and that is operator precedence parser(provided by Wiki):</p><pre><code class="nohighlight hljs">parse_expression()
    return parse_expression_1(parse_primary(), 0)
parse_expression_1(lhs, min_precedence)
    lookahead := peek next token
    while lookahead is a binary operator whose precedence is &gt;= min_precedence
        op := lookahead
        advance to next token
        rhs := parse_primary ()
        lookahead := peek next token
        while lookahead is a binary operator whose precedence is greater
                 than op&#39;s, or a right-associative operator
                 whose precedence is equal to op&#39;s
            rhs := parse_expression_1 (rhs, lookahead&#39;s precedence)
            lookahead := peek next token
        lhs := the result of applying op with operands lhs and rhs
    return lhs</code></pre><h2 id="Combinator"><a class="docs-heading-anchor" href="#Combinator">Combinator</a><a id="Combinator-1"></a><a class="docs-heading-anchor-permalink" href="#Combinator" title="Permalink"></a></h2><p>Finally, my favourite technology is combinator, here is the reason:</p><pre><code class="language-racket hljs">#lang racket

(require data/monad data/applicative) ;;; raco pkg install functional-lib
(require megaparsack megaparsack/text) ;;; raco pkg install megaparsack

(define lexeme/p
  ;;; lexeme would take at least one space or do nothing
  (do (or/p (many+/p space/p) void/p)
    (pure (λ () &#39;lexeme))))
(define (keyword/p keyword)
  (do (string/p keyword)
    (lexeme/p)
    (pure keyword)))
(define identifier/p
  (do [id &lt;- (many+/p letter/p)]
    (lexeme/p)
    (pure (list-&gt;string id))))
(define (type/p ctx)
  (do [check-struct &lt;- (or/p (keyword/p &quot;struct&quot;) void/p)]
    [typ &lt;- identifier/p]
    (pure ((λ ()
             (context/lookup-type-id ctx typ (eqv? check-struct &quot;struct&quot;)))))))

(define (struct-field/p ctx)
  (do [field &lt;- (list/p (type/p ctx) identifier/p)]
    (char/p #\;)
    (lexeme/p)
    (pure field)))
(define (struct-def/p ctx)
  (do (keyword/p &quot;struct&quot;)
    [name &lt;- identifier/p]
    (char/p #\{)
    (lexeme/p)
    [fields &lt;- (many/p (struct-field/p ctx))]
    (lexeme/p)
    (char/p #\})
    (pure ((λ ()
             (context/new-type ctx name (CStruct name fields))
             (CStructDef name fields))))))</code></pre><p>This just show how to parse a C structure definition using Racket combinator lib: <code>megaparsack</code>. Basically just as BNF definition, but with action easier and still using original language is the point.</p><p>Quickly the problem would be how to make operator precedence parsing, because combinator doesn&#39;t good at loop directly, however, combinator good at recursive:</p><pre><code class="language-racket hljs">#lang racket

(require data/monad data/applicative)
(require megaparsack megaparsack/text)

(define lexeme/p
  ;;; lexeme would take at least one space or do nothing
  (do (or/p (many+/p space/p) void/p)
    (pure (λ () &#39;lexeme))))

(define (op/p op-list)
  (or/p (one-of/p op-list)
        void/p))
(define factor/p
  (do [expr &lt;- integer/p]
    (lexeme/p)
    (pure expr)))
(define (binary/p high-level/p op-list)
  (do [e &lt;- high-level/p]
    ; `es` parse operator then high-level unit, for example, `* 1`.
    ; therefore, this parser would stop when the operator is not expected(aka. operator is in op-list)
    ; rely on this fact we can leave this loop
    [es &lt;- (many/p (do [op &lt;- (op/p op-list)]
                     (lexeme/p)
                     [e &lt;- high-level/p]
                     (pure (list op e))))]
    (pure (foldl
           (λ (op+rhs lhs)
             (match op+rhs
               [(list op rhs)
                (list op lhs rhs)]))
           e es))))
(define (table/p base/p list-of-op-list)
  (if (empty? list-of-op-list)
      base/p
      (table/p (binary/p base/p (car list-of-op-list))
               (cdr list-of-op-list))))
(define expr/p
  (table/p factor/p
           &#39;((#\* #\/)
             (#\+ #\-))))</code></pre><p>The code shows how to define table parser, and it even more simple to extend, all we need to do is just add new operator list into the table.</p><h2 id="Conclusion"><a class="docs-heading-anchor" href="#Conclusion">Conclusion</a><a id="Conclusion-1"></a><a class="docs-heading-anchor-permalink" href="#Conclusion" title="Permalink"></a></h2><p>Now we already shows all technologies for parsing(at least, what I know), now you can make some simple language by your own, but let me warn you: make a language doesn&#39;t easy, make it be runnable is just the first step, you need to make editor plugin(and we can&#39;t naively rely on parser I tell you here, since they cannot partially handle syntax), powerful debugger, profiler, and many other things to help people work on this language productively.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../chapter_10/">« Chapter 10: Refinement Type</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.10 on <span class="colophon-date" title="Sunday 19 December 2021 09:47">Sunday 19 December 2021</span>. Using Julia version 1.7.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
